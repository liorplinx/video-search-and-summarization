{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Video Search & Summarization (VSS) â€” A100 Single-GPU (80GB) Local Deployment\n",
    "\n",
    "This notebook deploys VSS on a **single A100 (80GB)** instance with **all models running locally**:\n",
    "- Cosmos Reason1 VLM (inside the VSS engine container)\n",
    "- LLM NIM (local)\n",
    "- Embedding NIM (local)\n",
    "- Reranker NIM (local)\n",
    "\n",
    "It uses the repo's **single-GPU docker compose** at `deploy/docker/local_deployment_single_gpu/compose.yaml`.\n",
    "\n",
    "Notes:\n",
    "- This notebook is designed for **1 GPU only**.\n",
    "- It does **not** assume `/ephemeral` storage.\n",
    "- It does **not** modify Docker daemon settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Prerequisites\n",
    "\n",
    "You need:\n",
    "- NVIDIA driver + CUDA working (`nvidia-smi` should show the A100)\n",
    "- Docker + Docker Compose v2\n",
    "- An `NGC_API_KEY` with access to the required images/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------\n",
    "# REQUIRED: set your NGC API key\n",
    "# ---------------------------\n",
    "os.environ.setdefault(\"NGC_API_KEY\", \"***\")  # TODO: replace\n",
    "\n",
    "# Resolve repo root robustly\n",
    "try:\n",
    "    VSS_REPO_DIR = subprocess.check_output(\n",
    "        [\"git\", \"rev-parse\", \"--show-toplevel\"],\n",
    "        text=True,\n",
    "        stderr=subprocess.STDOUT,\n",
    "    ).strip()\n",
    "except Exception:\n",
    "    VSS_REPO_DIR = str(Path.cwd().resolve().parent)\n",
    "\n",
    "os.environ[\"VSS_REPO_DIR\"] = VSS_REPO_DIR\n",
    "\n",
    "COMPOSE_DIR = str(Path(VSS_REPO_DIR) / \"deploy\" / \"docker\" / \"local_deployment_single_gpu\")\n",
    "os.environ[\"VSS_COMPOSE_DIR\"] = COMPOSE_DIR\n",
    "\n",
    "print(\"VSS_REPO_DIR=\", VSS_REPO_DIR)\n",
    "print(\"VSS_COMPOSE_DIR=\", COMPOSE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Configure deployment settings (A100 single-GPU baseline)\n",
    "\n",
    "This section sets:\n",
    "- Local data directories (host-mounted)\n",
    "- Ports\n",
    "- Cosmos Reason1 VLM selection\n",
    "- Conservative GPU-memory defaults for running *everything on one GPU*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "home = Path.home().resolve()\n",
    "data_root = (home / \"vss-data\").resolve()\n",
    "\n",
    "# Host paths (avoid filling container layers on a 256GB disk)\n",
    "asset_dir = (data_root / \"assets\").resolve()\n",
    "milvus_dir = (data_root / \"milvus\").resolve()\n",
    "nim_cache_dir = (data_root / \"nim-cache\").resolve()\n",
    "ngc_model_cache_dir = (data_root / \"ngc-model-cache\").resolve()\n",
    "via_logs_dir = (data_root / \"via-logs\").resolve()\n",
    "trt_engine_dir = (data_root / \"trt-engines\").resolve()\n",
    "\n",
    "for p in [asset_dir, milvus_dir, nim_cache_dir, ngc_model_cache_dir, via_logs_dir, trt_engine_dir]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ports\n",
    "os.environ.setdefault(\"BACKEND_PORT\", \"8100\")\n",
    "os.environ.setdefault(\"FRONTEND_PORT\", \"9100\")\n",
    "\n",
    "# DB credentials (local dev defaults)\n",
    "os.environ.setdefault(\"GRAPH_DB_USERNAME\", \"neo4j\")\n",
    "os.environ.setdefault(\"GRAPH_DB_PASSWORD\", \"password\")\n",
    "os.environ.setdefault(\"ARANGO_DB_USERNAME\", \"root\")\n",
    "os.environ.setdefault(\"ARANGO_DB_PASSWORD\", \"password\")\n",
    "\n",
    "# Host mounts\n",
    "os.environ[\"ASSET_STORAGE_DIR\"] = str(asset_dir)\n",
    "os.environ[\"NGC_MODEL_CACHE\"] = str(ngc_model_cache_dir)\n",
    "os.environ[\"VIA_LOG_DIR\"] = str(via_logs_dir)\n",
    "os.environ[\"TRT_ENGINE_PATH\"] = str(trt_engine_dir)\n",
    "os.environ[\"LOCAL_NIM_CACHE\"] = str(nim_cache_dir)\n",
    "\n",
    "# Compose + config mounts (important so the VSS container uses the local NIM endpoints)\n",
    "compose_dir = Path(os.environ[\"VSS_COMPOSE_DIR\"]).resolve()\n",
    "compose_yaml = (compose_dir / \"compose.yaml\").resolve()\n",
    "ca_rag_cfg = (compose_dir / \"config.yaml\").resolve()\n",
    "guardrails_dir = (compose_dir / \"guardrails\").resolve()\n",
    "\n",
    "if not compose_yaml.exists():\n",
    "    raise FileNotFoundError(f\"compose.yaml not found: {compose_yaml}\")\n",
    "if not ca_rag_cfg.exists():\n",
    "    raise FileNotFoundError(f\"config.yaml not found: {ca_rag_cfg}\")\n",
    "if not guardrails_dir.exists():\n",
    "    raise FileNotFoundError(f\"guardrails dir not found: {guardrails_dir}\")\n",
    "\n",
    "os.environ[\"CA_RAG_CONFIG\"] = str(ca_rag_cfg)\n",
    "os.environ[\"GUARDRAILS_CONFIG\"] = str(guardrails_dir)\n",
    "\n",
    "# This env var is used by compose.yaml to persist Milvus data (mounted into milvus-standalone at /var/lib/milvus).\n",
    "os.environ[\"MILVUS_DATA_DIR\"] = str(milvus_dir)\n",
    "\n",
    "# VLM: Cosmos Reason1 (local)\n",
    "os.environ[\"VLM_MODEL_TO_USE\"] = \"cosmos-reason1\"\n",
    "\n",
    "# MODEL_PATH should point to a local model directory OR a supported remote spec (e.g. hf/git/ngc).\n",
    "os.environ.setdefault(\"MODEL_PATH\", \"git:https://huggingface.co/nvidia/Cosmos-Reason1-7B\")\n",
    "\n",
    "# Single GPU only\n",
    "os.environ[\"NUM_GPUS\"] = \"1\"\n",
    "os.environ[\"NIM_GPU_DEVICE\"] = \"0\"\n",
    "\n",
    "# GPU memory knobs (because LLM + embed + reranker + VLM share the same A100)\n",
    "os.environ.setdefault(\"TRT_LLM_MEM_USAGE_FRACTION\", \"0.6\")\n",
    "os.environ.setdefault(\"VLLM_GPU_MEMORY_UTILIZATION\", \"0.6\")\n",
    "\n",
    "# Conservative batching\n",
    "os.environ.setdefault(\"VLM_BATCH_SIZE\", \"8\")\n",
    "\n",
    "# Optional features\n",
    "os.environ.setdefault(\"DISABLE_CV_PIPELINE\", \"true\")\n",
    "os.environ.setdefault(\"ENABLE_AUDIO\", \"false\")\n",
    "os.environ.setdefault(\"DISABLE_GUARDRAILS\", \"true\")\n",
    "\n",
    "# Keep assets bounded on a 256GB disk (optional)\n",
    "os.environ.setdefault(\"MAX_ASSET_STORAGE_SIZE_GB\", \"80\")\n",
    "\n",
    "print(\"Configured host data root:\", data_root)\n",
    "print(\"VSS_COMPOSE_DIR=\", str(compose_dir))\n",
    "print(\"compose.yaml=\", str(compose_yaml))\n",
    "print(\"CA_RAG_CONFIG=\", os.environ[\"CA_RAG_CONFIG\"])\n",
    "print(\"GUARDRAILS_CONFIG=\", os.environ[\"GUARDRAILS_CONFIG\"])\n",
    "print(\"BACKEND_PORT=\", os.environ[\"BACKEND_PORT\"], \"FRONTEND_PORT=\", os.environ[\"FRONTEND_PORT\"])\n",
    "print(\"VLM_MODEL_TO_USE=\", os.environ[\"VLM_MODEL_TO_USE\"])\n",
    "print(\"MODEL_PATH=\", os.environ[\"MODEL_PATH\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Log in to NGC (Docker)\n",
    "This is required to pull NIM images and the VSS engine image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "if [ -z \"${NGC_API_KEY:-}\" ] || [ \"${NGC_API_KEY}\" = \"***\" ]; then\n",
    "  echo \"ERROR: Please set NGC_API_KEY in the notebook cell above.\"\n",
    "  exit 1\n",
    "fi\n",
    "echo \"${NGC_API_KEY}\" | docker login nvcr.io -u '$oauthtoken' --password-stdin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Start the stack (VSS + local NIMs + databases)\n",
    "This uses docker compose in `deploy/docker/local_deployment_single_gpu`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "cd \"${VSS_COMPOSE_DIR}\"\n",
    "docker compose up -d --quiet-pull\n",
    "docker compose ps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Wait for services to become ready\n",
    "We check:\n",
    "- LLM NIM (`http://localhost:8000/v1/health/ready`)\n",
    "- Embedding NIM (`http://localhost:8006/v1/health/ready`)\n",
    "- Reranker NIM (`http://localhost:8005/v1/health/ready`)\n",
    "- VSS backend (`http://localhost:${BACKEND_PORT}/health/ready`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def wait_ready(url: str, timeout_s: int = 1800, interval_s: int = 5):\n",
    "    start = time.time()\n",
    "    last_err = None\n",
    "    while time.time() - start < timeout_s:\n",
    "        try:\n",
    "            r = requests.get(url, timeout=3)\n",
    "            if r.status_code == 200:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "        time.sleep(interval_s)\n",
    "    raise RuntimeError(f\"Timed out waiting for ready: {url} (last_err={last_err})\")\n",
    "\n",
    "backend_port = os.environ[\"BACKEND_PORT\"]\n",
    "checks = [\n",
    "    (\"LLM NIM\", \"http://localhost:8000/v1/health/ready\"),\n",
    "    (\"Embedding NIM\", \"http://localhost:8006/v1/health/ready\"),\n",
    "    (\"Reranker NIM\", \"http://localhost:8005/v1/health/ready\"),\n",
    "    (\"VSS Backend\", f\"http://localhost:{backend_port}/health/ready\"),\n",
    "]\n",
    "\n",
    "for name, url in checks:\n",
    "    print(f\"Waiting for {name}: {url}\")\n",
    "    wait_ready(url)\n",
    "    print(f\"{name} is ready\")\n",
    "\n",
    "print(\"All services are ready.\")\n",
    "print(\"Backend URL: \", f\"http://localhost:{backend_port}\")\n",
    "print(\"Frontend URL: \", f\"http://localhost:{os.environ['FRONTEND_PORT']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) (Optional) View logs\n",
    "If something is slow (first run model download/engine build), tail logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "cd \"${VSS_COMPOSE_DIR}\"\n",
    "docker compose logs --no-color --tail=200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Shutdown / cleanup\n",
    "Bring the stack down when finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "cd \"${VSS_COMPOSE_DIR}\"\n",
    "docker compose down\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
